import gradio as gr
import pymupdf  # PyMuPDF
import pandas as pd
from pydantic_ai import Agent
from pydantic import BaseModel
from typing import List, Optional
import google.generativeai as genai
import openai
import os
from dotenv import load_dotenv
import io
import json
import re

class Reference(BaseModel):
    authors: List[str]
    title: str
    journal: Optional[str] = None
    year: Optional[int] = None
    volume: Optional[str] = None
    pages: Optional[str] = None
    doi: Optional[str] = None

class ReferencesResponse(BaseModel):
    references: List[Reference]

def extract_pdf_text(pdf_file):
    """Extrai texto e metadados b√°sicos do PDF"""
    try:
        # Abrir o PDF com PyMuPDF
        doc = pymupdf.open(stream=pdf_file, filetype="pdf")
        
        # Extrair texto de todas as p√°ginas
        full_text = ""
        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            full_text += page.get_text() + "\n"
        
        # Extrair metadados b√°sicos
        metadata_dict = doc.metadata
        metadata = {
            "num_pages": len(doc),
            "title": metadata_dict.get('title', 'N√£o dispon√≠vel') if metadata_dict.get('title') else 'N√£o dispon√≠vel',
            "author": metadata_dict.get('author', 'N√£o dispon√≠vel') if metadata_dict.get('author') else 'N√£o dispon√≠vel',
            "subject": metadata_dict.get('subject', 'N√£o dispon√≠vel') if metadata_dict.get('subject') else 'N√£o dispon√≠vel',
            "creator": metadata_dict.get('creator', 'N√£o dispon√≠vel') if metadata_dict.get('creator') else 'N√£o dispon√≠vel'
        }
        
        # Fechar o documento
        doc.close()
        
        return full_text, metadata
    except Exception as e:
        return None, {"error": f"Erro ao processar PDF: {str(e)}"}

def extract_references_with_llm(text, model_name):
    """Usa Pydantic AI com diferentes modelos para extrair e estruturar refer√™ncias"""
    try:
        # Determinar se √© modelo Google ou OpenAI
        if model_name.startswith('gemini'):
            # Configurar a API key do Google
            genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
            api_key = os.getenv("GOOGLE_API_KEY")
        else:
            # Usar OpenAI
            api_key = os.getenv("OPENAI_API_KEY")
        
        if not api_key:
            return [{"error": f"Chave da API n√£o encontrada para o modelo {model_name}"}]
        
        # Criar o agente Pydantic AI
        agent = Agent(
            model_name,
            result_type=ReferencesResponse,
            system_prompt="""
            Voc√™ √© um especialista em an√°lise de artigos cient√≠ficos. 
            Sua tarefa √© identificar e extrair APENAS a se√ß√£o de refer√™ncias bibliogr√°ficas do texto fornecido.
            
            Para cada refer√™ncia encontrada, extraia:
            - authors: lista completa de autores
            - title: t√≠tulo completo do trabalho
            - journal: nome da revista/confer√™ncia/editora
            - year: ano de publica√ß√£o
            - volume: volume (se dispon√≠vel)
            - pages: p√°ginas (se dispon√≠vel)
            - doi: DOI (se dispon√≠vel)
            
            Seja preciso e extraia refer√™ncias completas.
            """
        )
        
        # Ajustar limite de texto baseado no modelo
        if model_name.startswith('gemini'):
            limited_text = text[:1500000]  # Gemini tem limite maior
        else:
            limited_text = text[:500000]   # OpenAI tem limite menor
        
        # Executar o agente
        result = agent.run_sync(f"Extraia as refer√™ncias bibliogr√°ficas do seguinte texto de artigo cient√≠fico:\n\n{limited_text}")
        
        # Converter para lista de dicion√°rios para compatibilidade com DataFrame
        references_list = []
        for ref in result.data.references:
            references_list.append({
                "authors": ", ".join(ref.authors) if ref.authors else "",
                "title": ref.title,
                "journal": ref.journal or "",
                "year": ref.year or "",
                "volume": ref.volume or "",
                "pages": ref.pages or "",
                "doi": ref.doi or ""
            })
        
        return references_list
            
    except Exception as e:
        return [{"error": f"Erro ao processar com LLM ({model_name}): {str(e)}"}]

def extract_references_with_regex(text):
    """Extrai refer√™ncias usando express√µes regulares em todo o texto"""
    try:
        references = []
        
        # Padr√µes melhorados para extrair refer√™ncias individuais
        patterns = [
            # Padr√£o 0: Refer√™ncias numeradas com ponto (ex: 46. Autor et al. T√≠tulo. Journal vol, pages (ano).)
            r'^\d+\.\s*([A-Z][A-Za-z\s,&.-]*?et\s+al\.?|[A-Z][A-Za-z\s,&.-]+?)\.\s*([^.]+?)\.\s*([^.]+?)\s+(\d+),?\s*[\d‚Äì-]+\s*\((\d{4})\)\.',
            
            # Padr√£o 1: Autor(es). (Ano). T√≠tulo. Journal/Editora.
            r'^([A-Z][A-Za-z\s,&.-]+?)\.\s*\((\d{4}[a-z]?)\)\.\s*([^.]+?)\.\s*([^.]+?)\.?\s*$',
            
            # Padr√£o 2: Refer√™ncias numeradas [1] Autor...
            r'^\[\d+\]\s*([A-Z][A-Za-z\s,&.-]+?)\.\s*\((\d{4}[a-z]?)\)\.\s*([^.]+?)\.\s*([^.]+?)\.?\s*$',
            
            # Padr√£o 3: Autor, A. (Ano). T√≠tulo. Journal.
            r'^([A-Z][A-Za-z\s,&.-]+?)\s+\((\d{4}[a-z]?)\)[.,]\s*([^.]+?)[.,]\s*([^.]+?)\.?\s*$',
            
            # Padr√£o 4: Autor et al. (Ano) T√≠tulo. Journal
            r'^([A-Z][A-Za-z\s,&.-]*?et\s+al\.?)\s*\((\d{4}[a-z]?)\)[.,]?\s*([^.]+?)[.,]\s*([^.]+?)\.?\s*$',
            
            # Padr√£o 5: Sobrenome, Nome (Ano). T√≠tulo. Journal.
            r'^([A-Z][a-z]+,\s*[A-Z][A-Za-z\s,&.-]*?)\.\s*\((\d{4}[a-z]?)\)\.\s*([^.]+?)\.\s*([^.]+?)\.?\s*$',
            
            # Padr√£o 6: M√∫ltiplos autores com &
            r'^([A-Z][A-Za-z\s,&.-]+?&[A-Za-z\s,&.-]+?)\.\s*\((\d{4}[a-z]?)\)\.\s*([^.]+?)\.\s*([^.]+?)\.?\s*$'
        ]
        
        # Dividir texto em linhas
        lines = text.split('\n')
        
        # Processar cada linha
        for line_num, line in enumerate(lines):
            line = line.strip()
            
            # Pular linhas muito curtas ou que n√£o come√ßam com letra mai√∫scula
            if len(line) < 20 or not line[0].isupper():
                continue
            
            # Pular linhas que s√£o claramente t√≠tulos de se√ß√£o
            if re.match(r'^(abstract|introduction|methods?|results?|discussion|conclusion|references?|bibliography|acknowledgments?)\.?\s*$', line, re.IGNORECASE):
                continue
            
            # Tentar cada padr√£o
            for pattern in patterns:
                match = re.match(pattern, line, re.MULTILINE | re.IGNORECASE)
                
                if match:
                    groups = match.groups()
                    if len(groups) >= 4:
                        authors = groups[0].strip()
                        
                        # Para o padr√£o numerado especial (5 grupos)
                        if len(groups) == 5:
                            title = groups[1].strip()
                            journal = groups[2].strip()
                            volume = groups[3].strip()
                            year = groups[4].strip()
                            pages = ""  # Ser√° extra√≠do depois do journal
                        else:
                            # Para outros padr√µes (4 grupos)
                            year = groups[1].strip()
                            title = groups[2].strip()
                            journal = groups[3].strip()
                            volume = ""
                    
                    # Valida√ß√µes adicionais
                    # Verificar se tem pelo menos um autor v√°lido
                    if not re.search(r'[A-Z][a-z]+', authors):
                        continue
                    
                    # Verificar se o t√≠tulo n√£o √© muito curto
                    if len(title) < 10:
                        continue
                    
                    # Verificar se n√£o √© uma linha de cabe√ßalho ou rodap√©
                    if re.search(r'(page|vol|volume|number|issue)\s*\d+', line, re.IGNORECASE):
                        continue
                    
                    # Extrair DOI se presente
                    doi_match = re.search(r'doi[:\s]*([^\s,]+)', journal, re.IGNORECASE)
                    doi = doi_match.group(1) if doi_match else ""
                    
                    # Extrair volume e p√°ginas (se n√£o foram extra√≠dos pelo padr√£o especial)
                    if len(groups) != 5:
                        vol_pages_match = re.search(r'(\d+)\s*\(?\d*\)?\s*[,:]\s*(\d+[-‚Äì]\d+)', journal)
                        volume = vol_pages_match.group(1) if vol_pages_match else ""
                        pages = vol_pages_match.group(2) if vol_pages_match else ""
                    else:
                        # Para o padr√£o numerado, extrair p√°ginas do journal
                        pages_match = re.search(r'(\d+[-‚Äì]\d+)', journal)
                        pages = pages_match.group(1) if pages_match else ""
                    
                    # Limpar campos
                    authors = re.sub(r'\s+', ' ', authors)
                    title = re.sub(r'\s+', ' ', title)
                    journal = re.sub(r'\s+', ' ', journal)
                    
                    reference = {
                        "authors": authors,
                        "title": title,
                        "journal": journal,
                        "year": year,
                        "volume": volume,
                        "pages": pages,
                        "doi": doi,
                        "line_number": line_num + 1  # Para debug
                    }
                    
                    references.append(reference)
                    break  # Parar na primeira correspond√™ncia para esta linha
        
        # Remover duplicatas baseadas no t√≠tulo e ano
        seen_refs = set()
        unique_references = []
        
        for ref in references:
            # Criar chave √∫nica baseada em t√≠tulo e ano
            key = (ref["title"].lower().strip()[:50], ref["year"])
            
            if key not in seen_refs:
                seen_refs.add(key)
                # Remover campo de debug antes de retornar
                ref_clean = {k: v for k, v in ref.items() if k != "line_number"}
                unique_references.append(ref_clean)
        
        # Ordenar por ano (mais recente primeiro)
        unique_references.sort(key=lambda x: x.get("year", "0"), reverse=True)
        
        return unique_references[:100]  # Limitar a 100 refer√™ncias
        
    except Exception as e:
        return [{"error": f"Erro na extra√ß√£o por regex: {str(e)}"}]

def create_highlighted_text(text, regex_references):
    """Cria HTML com texto destacado onde foram encontradas refer√™ncias por regex"""
    try:
        # Dividir texto em linhas
        lines = text.split('\n')
        highlighted_lines = []
        
        # Padr√µes para destacar (mesmos da extra√ß√£o)
        patterns = [
            r'^\d+\.\s*([A-Z][A-Za-z\s,&.-]*?et\s+al\.?|[A-Z][A-Za-z\s,&.-]+?)\.\s*([^.]+?)\.\s*([^.]+?)\s+(\d+),?\s*[\d‚Äì-]+\s*\((\d{4})\)\.',
            r'^([A-Z][A-Za-z\s,&.-]+?)\.\s*\((\d{4}[a-z]?)\)\.\s*([^.]+?)\.\s*([^.]+?)\.?\s*$',
            r'^\[\d+\]\s*([A-Z][A-Za-z\s,&.-]+?)\.\s*\((\d{4}[a-z]?)\)\.\s*([^.]+?)\.\s*([^.]+?)\.?\s*$',
            r'^([A-Z][A-Za-z\s,&.-]+?)\s+\((\d{4}[a-z]?)\)[.,]\s*([^.]+?)[.,]\s*([^.]+?)\.?\s*$',
            r'^([A-Z][A-Za-z\s,&.-]*?et\s+al\.?)\s*\((\d{4}[a-z]?)\)[.,]?\s*([^.]+?)[.,]\s*([^.]+?)\.?\s*$',
            r'^([A-Z][a-z]+,\s*[A-Z][A-Za-z\s,&.-]*?)\.\s*\((\d{4}[a-z]?)\)\.\s*([^.]+?)\.\s*([^.]+?)\.?\s*$',
            r'^([A-Z][A-Za-z\s,&.-]+?&[A-Za-z\s,&.-]+?)\.\s*\((\d{4}[a-z]?)\)\.\s*([^.]+?)\.\s*([^.]+?)\.?\s*$'
        ]
        
        colors = ['#ff5722', '#ffeb3b', '#4caf50', '#2196f3', '#ff9800', '#9c27b0', '#e91e63']
        
        # Processar cada linha
        for line in lines:
            original_line = line
            line_stripped = line.strip()
            
            # Verificar se a linha corresponde a algum padr√£o
            matched = False
            for i, pattern in enumerate(patterns):
                if re.match(pattern, line_stripped, re.MULTILINE | re.IGNORECASE):
                    if len(line_stripped) >= 20 and line_stripped[0].isupper():
                        color = colors[i % len(colors)]
                        highlighted_line = f'<span style="background-color: {color}; padding: 2px; border-radius: 3px; display: block; margin: 1px 0;" title="Padr√£o {i+1}">{original_line}</span>'
                        highlighted_lines.append(highlighted_line)
                        matched = True
                        break
            
            if not matched:
                highlighted_lines.append(original_line)
        
        # Criar HTML final
        html_content = '<br>'.join(highlighted_lines)
        
        styled_html = f"""
        <div style="
            font-family: 'Courier New', monospace;
            font-size: 12px;
            line-height: 1.4;
            max-height: 400px;
            overflow-y: auto;
            padding: 15px;
            border: 1px solid #ddd;
            border-radius: 5px;
            background-color: #fafafa;
            white-space: pre-wrap;
        ">
            <div style="margin-bottom: 10px; font-weight: bold; color: #333;">
                üìÑ Texto Extra√≠do com Destaques das Refer√™ncias
            </div>
            <div style="margin-bottom: 15px; font-size: 11px; color: #666;">
                <span style="background-color: #ff5722; padding: 2px;">‚ñ†</span> Padr√£o 0 &nbsp;
                <span style="background-color: #ffeb3b; padding: 2px;">‚ñ†</span> Padr√£o 1 &nbsp;
                <span style="background-color: #4caf50; padding: 2px;">‚ñ†</span> Padr√£o 2 &nbsp;
                <span style="background-color: #2196f3; padding: 2px;">‚ñ†</span> Padr√£o 3 &nbsp;
                <span style="background-color: #ff9800; padding: 2px;">‚ñ†</span> Padr√£o 4 &nbsp;
                <span style="background-color: #9c27b0; padding: 2px;">‚ñ†</span> Padr√£o 5 &nbsp;
                <span style="background-color: #e91e63; padding: 2px;">‚ñ†</span> Padr√£o 6
            </div>
            {html_content}
        </div>
        """
        
        return styled_html
        
    except Exception as e:
        return f"<div style='color: red;'>Erro ao criar texto destacado: {str(e)}</div>"

def process_pdf(pdf_file, model_name):
    """Fun√ß√£o principal que processa o PDF e retorna resultados"""
    if pdf_file is None:
        return {"error": "Nenhum arquivo enviado"}, pd.DataFrame(), pd.DataFrame(), "‚ùå Nenhum arquivo enviado", "<div>Nenhum texto para exibir</div>"
    
    # Extrair texto do PDF
    text, metadata = extract_pdf_text(pdf_file)
    
    if text is None:
        return metadata, pd.DataFrame(), pd.DataFrame(), "‚ùå Erro ao processar PDF", "<div style='color: red;'>Erro ao extrair texto</div>"
    
    # Adicionar modelo selecionado aos metadados
    metadata["modelo_usado"] = model_name
    metadata["caracteres_extraidos"] = len(text)
    metadata["palavras_aproximadas"] = len(text.split())
    
    # Extrair refer√™ncias com LLM
    llm_references = extract_references_with_llm(text, model_name)
    
    # Extrair refer√™ncias com Regex
    regex_references = extract_references_with_regex(text)
    
    # Criar HTML com destaques
    highlighted_html = create_highlighted_text(text, regex_references)
    
    # Converter para DataFrames
    if llm_references and not any("error" in ref for ref in llm_references):
        llm_df = pd.DataFrame(llm_references)
    else:
        llm_df = pd.DataFrame({"Erro": ["N√£o foi poss√≠vel extrair refer√™ncias com LLM"]})
    
    if regex_references and not any("error" in ref for ref in regex_references):
        regex_df = pd.DataFrame(regex_references)
    else:
        regex_df = pd.DataFrame({"Erro": ["N√£o foi poss√≠vel extrair refer√™ncias com Regex"]})
    
    # Criar status
    llm_count = len(llm_references) if llm_references and not any("error" in ref for ref in llm_references) else 0
    regex_count = len(regex_references) if regex_references and not any("error" in ref for ref in regex_references) else 0
    
    status = f"üìä **Resultados da Extra√ß√£o:**\n- LLM ({model_name}): {llm_count} refer√™ncias\n- Regex: {regex_count} refer√™ncias"
    
    return metadata, llm_df, regex_df, status, highlighted_html

def create_interface():
    """Cria a interface Gradio"""
    with gr.Blocks(title="Extrator de Refer√™ncias") as interface:
        gr.Markdown("# üìö Extrator de Refer√™ncias de Artigos Cient√≠ficos")
        gr.Markdown("Fa√ßa upload de um PDF de artigo cient√≠fico para extrair automaticamente a lista de refer√™ncias usando IA e express√µes regulares.")
        
        with gr.Row():
            with gr.Column():
                pdf_input = gr.File(
                    label="üìÑ Upload do PDF",
                    file_types=[".pdf"],
                    type="binary"
                )
            with gr.Column():
                model_dropdown = gr.Dropdown(
                    choices=[
                        "gemini-2.5-flash-lite",
                        "gemini-2.5-pro",
                        "gemini-2.5-flash",
                        "gpt-4o",
                        "gpt-o3-mini",
                        "gpt-4.1"
                    ],
                    value="gemini-2.5-flash-lite",
                    label="ü§ñ Modelo de IA",
                    info="Selecione o modelo para extrair as refer√™ncias"
                )
        
        extract_btn = gr.Button("üîç Extrair Refer√™ncias", variant="primary")
        
        with gr.Row():
            with gr.Column():
                metadata_output = gr.JSON(label="üìã Metadados do Artigo")
            with gr.Column():
                extracted_text_output = gr.HTML(
                    label="üìÑ Texto Extra√≠do com Destaques",
                )
        
        with gr.Row():
            with gr.Column():
                llm_references_output = gr.Dataframe(
                    label="ü§ñ Refer√™ncias Extra√≠das por IA",
                    row_count=(10,'dynamic'),
                    show_copy_button=True,
                    show_fullscreen_button=True,
                    wrap=True
                )
            with gr.Column():
                regex_references_output = gr.Dataframe(
                    label="üîç Refer√™ncias Extra√≠das por Regex",
                    row_count=(10,'dynamic'),
                    show_copy_button=True,
                    show_fullscreen_button=True,
                    wrap=True
                )
        
        status_output = gr.Markdown(label="üìä Status da Extra√ß√£o")
        
        extract_btn.click(
            process_pdf,
            inputs=[pdf_input, model_dropdown],
            outputs=[metadata_output, llm_references_output, regex_references_output, status_output, extracted_text_output]
        )
    
    return interface

def main():
    load_dotenv()  # Carrega vari√°veis de ambiente do arquivo .env
    
    # Verificar se as chaves das APIs est√£o configuradas
    google_key = os.getenv("GOOGLE_API_KEY")
    openai_key = os.getenv("OPENAI_API_KEY")
    
    if not google_key and not openai_key:
        print("‚ö†Ô∏è  AVISO: Nenhuma chave de API encontrada!")
        print("Configure pelo menos uma das seguintes no arquivo .env:")
        print("- GEMINI_API_KEY=sua_chave_do_google")
        print("- OPENAI_API_KEY=sua_chave_da_openai")
    elif not google_key:
        print("‚ÑπÔ∏è  Apenas OpenAI configurado. Modelos Gemini n√£o funcionar√£o.")
    elif not openai_key:
        print("‚ÑπÔ∏è  Apenas Google configurado. Modelos OpenAI n√£o funcionar√£o.")
    
    interface = create_interface()
    interface.launch(share=False)

if __name__ == "__main__":
    main()
