import gradio as gr
import pymupdf  # PyMuPDF
import pandas as pd
from pydantic_ai import Agent
from pydantic_ai.settings import ModelSettings
from pydantic import BaseModel
from typing import List, Optional
import google.generativeai as genai
import openai
import os
from dotenv import load_dotenv
import io
import json
import re

# Padr√µes globais de regex para extra√ß√£o de refer√™ncias
REFERENCE_PATTERNS = [
    # Padr√£o 0: Refer√™ncias numeradas com autores m√∫ltiplos (formato: N√∫mero. Autores. T√≠tulo. Journal info (ano).)
    r'^\d+\.\s*([A-Z][A-Za-z\s,&.-]+?(?:\s&\s[A-Z][A-Za-z\s,&.-]+?)*)\.\s*([^.]+?)\.\s*([^.]+?)\s+(\d+),?\s*([^(]*?)\s*\((\d{4})\)',
    
    # Padr√£o 1: Autor(es). (Ano). T√≠tulo. Journal/Editora.
    r'^([A-Z][A-Za-z\s,&.-]+?)\.\s*\((\d{4}[a-z]?)\)\.\s*([^.]+?)\.\s*([^.]+?)\.?\s*$',
    
    # Padr√£o 2: Refer√™ncias numeradas [1] Autor... ano T√≠tulo. Journal doi:...
    r'^\[\d+\]\s*([A-Z][A-Za-z\s,&.-]+?)\s+(\d{4})\s+([^.]+?)\.\s*([^.]+?)(?:\s+doi:([^\s.]+))?\.?\s*$',
    
    # Padr√£o 3: Autor, A. (Ano). T√≠tulo. Journal.
    r'^([A-Z][A-Za-z\s,&.-]+?)\s+\((\d{4}[a-z]?)\)[.,]\s*([^.]+?)[.,]\s*([^.]+?)\.?\s*$',
    
    # Padr√£o 4: Autor et al. (Ano) T√≠tulo. Journal
    r'^([A-Z][A-Za-z\s,&.-]*?et\s+al\.?)\s*\((\d{4}[a-z]?)\)[.,]?\s*([^.]+?)[.,]\s*([^.]+?)\.?\s*$',
    
    # Padr√£o 5: Sobrenome, Nome (Ano). T√≠tulo. Journal.
    r'^([A-Z][a-z]+,\s*[A-Z][A-Za-z\s,&.-]*?)\.\s*\((\d{4}[a-z]?)\)\.\s*([^.]+?)\.\s*([^.]+?)\.?\s*$',
    
    # Padr√£o 6: M√∫ltiplos autores com &
    r'^([A-Z][A-Za-z\s,&.-]+?&[A-Za-z\s,&.-]+?)\.\s*\((\d{4}[a-z]?)\)\.\s*([^.]+?)\.\s*([^.]+?)\.?\s*$',
    
    # Padr√£o 7: Refer√™ncias numeradas [n√∫mero] Autor: T√≠tulo, Editora (ano)
    r'^\[\d+\]\s*([A-Z][A-Za-z\s,&.-]+?):\s*([^,]+?),\s*([^(]+?)\s*\((\d{4})\)',

    # Padr√£o 8: Refer√™ncias numeradas com DOI opcional
r"""
^              # in√≠cio de linha (ap√≥s poss√≠vel marcador de ordem)
(?:\d+\.\s*)?  # n√∫mero da refer√™ncia (opcional), seguido de ponto e espa√ßo
(?P<autores>   # grupo 'autores'
  [^\.]+?      # tudo antes do primeiro ponto final (n√£o guloso)
)\.\s+
(?P<titulo>    # grupo 'titulo'
  [^\n\.]+     # at√© o pr√≥ximo ponto final ou quebra de linha
)\.
\s*
(?P<journal>   # grupo 'journal'
  [^\n;]+      # at√© o pr√≥ximo ponto e v√≠rgula (ou quebra de linha)
)
[;,]?\s*
(?P<ano>       # grupo 'ano'
  \d{4}        # 4 d√≠gitos (ano)
)
(?:;[^\n]*?)?  # volume, issue, p√°ginas (opcional, n√£o capturado)
(?:\n+         # nova linha(s), captura DOI opcional
  (?P<doi> https?://doi\.org/[^\s]+ )
)?             # DOI pode estar na linha de baixo ou ausente
"""
]

class Reference(BaseModel):
    authors: List[str]
    title: str
    journal: Optional[str] = None
    year: Optional[int] = None
    volume: Optional[str] = None
    pages: Optional[str] = None
    doi: Optional[str] = None

class ReferencesResponse(BaseModel):
    references: List[Reference]

def extract_pdf_text(pdf_file):
    """Extrai texto e metadados b√°sicos do PDF"""
    try:
        # Abrir o PDF com PyMuPDF
        doc = pymupdf.open(stream=pdf_file, filetype="pdf")
        
        # Extrair texto de todas as p√°ginas
        full_text = ""
        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            full_text += page.get_text() + "\n"
        
        # Extrair metadados b√°sicos
        metadata_dict = doc.metadata
        metadata = {
            "num_pages": len(doc),
            "title": metadata_dict.get('title', 'N√£o dispon√≠vel') if metadata_dict.get('title') else 'N√£o dispon√≠vel',
            "author": metadata_dict.get('author', 'N√£o dispon√≠vel') if metadata_dict.get('author') else 'N√£o dispon√≠vel',
            "subject": metadata_dict.get('subject', 'N√£o dispon√≠vel') if metadata_dict.get('subject') else 'N√£o dispon√≠vel',
            "creator": metadata_dict.get('creator', 'N√£o dispon√≠vel') if metadata_dict.get('creator') else 'N√£o dispon√≠vel'
        }
        
        # Fechar o documento
        doc.close()
        
        return full_text, metadata
    except Exception as e:
        return None, {"error": f"Erro ao processar PDF: {str(e)}"}

def extract_references_with_llm(text, model_name):
    """Usa Pydantic AI com diferentes modelos para extrair e estruturar refer√™ncias"""
    try:
        # Determinar se √© modelo Google ou OpenAI
        if model_name.startswith('gemini'):
            # Configurar a API key do Google
            genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
            api_key = os.getenv("GEMINI_API_KEY")
        else:
            # Usar OpenAI
            api_key = os.getenv("OPENAI_API_KEY")
        
        if not api_key:
            return [{"error": f"Chave da API n√£o encontrada para o modelo {model_name}"}]
        
        # Criar o agente Pydantic AI
        agent = Agent(
            model_name,
            model_settings=ModelSettings(
                timeout=30,
            ),
            output_type=ReferencesResponse,
            system_prompt="""
            Voc√™ √© um especialista em an√°lise de artigos cient√≠ficos. 
            Sua tarefa √© identificar e extrair APENAS a se√ß√£o de refer√™ncias bibliogr√°ficas do texto fornecido.
            
            Para cada refer√™ncia encontrada, extraia:
            - authors: lista completa de autores
            - title: t√≠tulo completo do trabalho
            - journal: nome da revista/confer√™ncia/editora
            - year: ano de publica√ß√£o
            - volume: volume (se dispon√≠vel)
            - pages: p√°ginas (se dispon√≠vel)
            - doi: DOI (se dispon√≠vel)
            
            Seja preciso e extraia refer√™ncias completas.
            """
        )
        
        # Ajustar limite de texto baseado no modelo
        if model_name.startswith('gemini'):
            limited_text = text[:1500000]  # Gemini tem limite maior
        else:
            limited_text = text[:500000]   # OpenAI tem limite menor
        
        # Executar o agente
        result = agent.run_sync(f"Extraia as refer√™ncias bibliogr√°ficas do seguinte texto de artigo cient√≠fico:\n\n{limited_text}")
        
        # Converter para lista de dicion√°rios para compatibilidade com DataFrame
        references_list = []
        for ref in result.output.references:
            references_list.append({
                "authors": ", ".join(ref.authors) if ref.authors else "",
                "title": ref.title,
                "journal": ref.journal or "",
                "year": ref.year or "",
                "volume": ref.volume or "",
                "pages": ref.pages or "",
                "doi": ref.doi or ""
            })
        
        return references_list
            
    except Exception as e:
        return [{"error": f"Erro ao processar com LLM ({model_name}): {str(e)}"}]

def extract_references_with_regex(text):
    """Extrai refer√™ncias usando express√µes regulares em todo o texto"""
    try:
        references = []
        
        # Processar cada padr√£o
        for pattern_index, pattern in enumerate(REFERENCE_PATTERNS):
            reflist = re.findall(pattern, text, re.MULTILINE | re.UNICODE | re.DOTALL| re.VERBOSE)

            if reflist:
                for ref_match in reflist:
                    groups = ref_match
                    
                    if len(groups) >= 4:
                        authors = groups[0].strip()

                        # Para o padr√£o numerado especial (6 grupos)
                        if len(groups) == 6:
                            title = groups[1].strip()
                            journal = groups[2].strip()
                            volume = groups[3].strip()
                            pages = groups[4].strip()
                            year = groups[5].strip()
                        # Para o padr√£o 7 (formato [n√∫mero] Autor: T√≠tulo, Editora (ano))
                        elif pattern_index == 7:
                            title = groups[1].strip()
                            journal = groups[2].strip()
                            year = groups[3].strip()
                            volume = ""
                        else:
                            # Para outros padr√µes (4 grupos)
                            year = groups[1].strip()
                            title = groups[2].strip()
                            journal = groups[3].strip()
                            volume = ""


                        # Extrair DOI se presente
                        doi_match = re.search(r'doi[:\s]*([^\s,]+)', journal, re.IGNORECASE)
                        doi = doi_match.group(1) if doi_match else ""

                        # Extrair volume e p√°ginas (se n√£o foram extra√≠dos pelo padr√£o especial)
                        if len(groups) != 6:
                            vol_pages_match = re.search(r'(\d+)\s*\(?\d*\)?\s*[,:]\s*(\d+[-‚Äì]\d+)', journal)
                            volume = vol_pages_match.group(1) if vol_pages_match else ""
                            pages = vol_pages_match.group(2) if vol_pages_match else ""
                        else:
                            # Para o padr√£o numerado, extrair p√°ginas do journal
                            pages_match = re.search(r'(\d+[-‚Äì]\d+)', journal)
                            pages = pages_match.group(1) if pages_match else ""

                        # Limpar campos
                        authors = re.sub(r'\s+', ' ', authors)
                        title = re.sub(r'\s+', ' ', title)
                        journal = re.sub(r'\s+', ' ', journal)

                        reference = {
                            "authors": authors,
                            "title": title,
                            "journal": journal,
                            "year": year,
                            "volume": volume,
                            "pages": pages,
                            "doi": doi
                        }

                        references.append(reference)


        return references
        
    except Exception as e:
        return [{"error": f"Erro na extra√ß√£o por regex: {str(e)}"}]

def create_plain_text(text, regex_references):
    """Retorna o texto extra√≠do como texto simples"""
    try:
        return text
        
    except Exception as e:
        return f"Erro ao processar texto: {str(e)}"

def process_pdf(pdf_file, model_name):
    """Fun√ß√£o principal que processa o PDF e retorna resultados"""
    if pdf_file is None:
        return {"error": "Nenhum arquivo enviado"}, pd.DataFrame(), pd.DataFrame(), "‚ùå Nenhum arquivo enviado", "Nenhum texto para exibir"
    
    # Extrair texto do PDF
    text, metadata = extract_pdf_text(pdf_file)
    
    if text is None:
        return metadata, pd.DataFrame(), pd.DataFrame(), "‚ùå Erro ao processar PDF", "Erro ao extrair texto"
    
    # Adicionar modelo selecionado aos metadados
    metadata["modelo_usado"] = model_name
    metadata["caracteres_extraidos"] = len(text)
    metadata["palavras_aproximadas"] = len(text.split())
    
    # Extrair refer√™ncias com LLM
    llm_references = extract_references_with_llm(text, model_name)
    
    # Extrair refer√™ncias com Regex
    regex_references = extract_references_with_regex(text)
    
    # Criar texto simples
    plain_text = create_plain_text(text, regex_references)
    
    # Converter para DataFrames
    if llm_references and not any("error" in ref for ref in llm_references):
        llm_df = pd.DataFrame(llm_references)
    else:
        llm_df = pd.DataFrame({"Erro": ["N√£o foi poss√≠vel extrair refer√™ncias com LLM"]})
    
    if regex_references and not any("error" in ref for ref in regex_references):
        regex_df = pd.DataFrame(regex_references)
    else:
        regex_df = pd.DataFrame({"Erro": ["N√£o foi poss√≠vel extrair refer√™ncias com Regex"]})
    
    # Criar status
    llm_count = len(llm_references) if llm_references and not any("error" in ref for ref in llm_references) else 0
    regex_count = len(regex_references) if regex_references and not any("error" in ref for ref in regex_references) else 0
    
    status = f"üìä **Resultados da Extra√ß√£o:**\n- LLM ({model_name}): {llm_count} refer√™ncias\n- Regex: {regex_count} refer√™ncias"
    
    return metadata, llm_df, regex_df, status, plain_text

def create_interface():
    """Cria a interface Gradio"""
    with gr.Blocks(title="Extrator de Refer√™ncias") as interface:
        gr.Markdown("# üìö Extrator de Refer√™ncias de Artigos Cient√≠ficos")
        gr.Markdown("Fa√ßa upload de um PDF de artigo cient√≠fico para extrair automaticamente a lista de refer√™ncias usando IA e express√µes regulares.")
        
        with gr.Row():
            with gr.Column():
                pdf_input = gr.File(
                    label="üìÑ Upload do PDF",
                    file_types=[".pdf"],
                    type="binary"
                )
            with gr.Column():
                model_dropdown = gr.Dropdown(
                    choices=[
                        "gemini-2.5-flash-lite",
                        "gemini-2.5-pro",
                        "gemini-2.5-flash",
                        "gpt-4o",
                        "gpt-o3-mini",
                        "gpt-4.1"
                    ],
                    value="gemini-2.5-flash-lite",
                    label="ü§ñ Modelo de IA",
                    info="Selecione o modelo para extrair as refer√™ncias"
                )
        
        extract_btn = gr.Button("üîç Extrair Refer√™ncias", variant="primary")
        
        with gr.Row():
            with gr.Column():
                metadata_output = gr.JSON(label="üìã Metadados do Artigo")
            with gr.Column():
                extracted_text_output = gr.Textbox(
                    label="üìÑ Texto Extra√≠do",
                    lines=20,
                    max_lines=20,
                    show_copy_button=True,
                    interactive=False
                )
        
        with gr.Row():
            with gr.Column():
                llm_references_output = gr.Dataframe(
                    label="ü§ñ Refer√™ncias Extra√≠das por IA",
                    row_count=(10,'dynamic'),
                    show_copy_button=True,
                    show_fullscreen_button=True,
                    wrap=True
                )
            with gr.Column():
                regex_references_output = gr.Dataframe(
                    label="üîç Refer√™ncias Extra√≠das por Regex",
                    row_count=(10,'dynamic'),
                    show_copy_button=True,
                    show_fullscreen_button=True,
                    wrap=True
                )
        
        status_output = gr.Markdown(label="üìä Status da Extra√ß√£o")
        
        extract_btn.click(
            process_pdf,
            inputs=[pdf_input, model_dropdown],
            outputs=[metadata_output, llm_references_output, regex_references_output, status_output, extracted_text_output]
        )
    
    return interface

def main():
    load_dotenv()  # Carrega vari√°veis de ambiente do arquivo .env
    
    # Verificar se as chaves das APIs est√£o configuradas
    google_key = os.getenv("GEMINI_API_KEY")
    openai_key = os.getenv("OPENAI_API_KEY")
    
    if not google_key and not openai_key:
        print("‚ö†Ô∏è  AVISO: Nenhuma chave de API encontrada!")
        print("Configure pelo menos uma das seguintes no arquivo .env:")
        print("- GEMINI_API_KEY=sua_chave_do_google")
        print("- OPENAI_API_KEY=sua_chave_da_openai")
    elif not google_key:
        print("‚ÑπÔ∏è  Apenas OpenAI configurado. Modelos Gemini n√£o funcionar√£o.")
    elif not openai_key:
        print("‚ÑπÔ∏è  Apenas Google configurado. Modelos OpenAI n√£o funcionar√£o.")
    
    interface = create_interface()
    interface.launch(share=False)

if __name__ == "__main__":
    main()
